{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms7JAobRQPZV",
        "outputId": "a34ca03f-4788-465f-f04a-703c32d59ccb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euq9N-qWQZi_"
      },
      "source": [
        "# Imports\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xURwkPRrQeHr"
      },
      "source": [
        "# Get train dataset and test dataset\n",
        "trainset = pd.read_csv(\"q3_train_dataset.csv\")\n",
        "testset = pd.read_csv(\"q3_test_dataset.csv\")\n",
        "\n",
        "# Separate labels from trainset and testset\n",
        "trainlabels = trainset[\"Survival Status\"].astype(int)\n",
        "testlabels = testset[\"Survival Status\"].astype(int)\n",
        "\n",
        "# Get features\n",
        "trainset = trainset[[\"Ticket Class\", \"Gender\", \"Age\", \"Siblings / Spouse\", \"Parent / Children\", \"Port of Embarkation\"]]\n",
        "testset = testset[[\"Ticket Class\", \"Gender\", \"Age\", \"Siblings / Spouse\", \"Parent / Children\", \"Port of Embarkation\"]]\n",
        "\n",
        "# Put 0 for male and 1 for female\n",
        "trainset[\"Gender\"].replace({\"male\":0, \"female\":1}, inplace=True)\n",
        "testset[\"Gender\"].replace({\"male\":0, \"female\":1}, inplace=True)\n",
        "\n",
        "# Put 0 for S, 1 for C, 2 for Q\n",
        "trainset[\"Port of Embarkation\"].replace({\"S\":0, \"C\":1, \"Q\":2}, inplace=True)\n",
        "testset[\"Port of Embarkation\"].replace({\"S\":0, \"C\":1, \"Q\":2}, inplace=True)\n",
        "\n",
        "# Convert float ages to integers (Maybe not needed)\n",
        "trainset[\"Age\"] = trainset[\"Age\"].astype(int)\n",
        "testset[\"Age\"] = testset[\"Age\"].astype(int)\n",
        "\n",
        "# Need to normalize data\n",
        "normalizedTrainset=(trainset-trainset.min())/(trainset.max()-trainset.min())\n",
        "normalizedTestset = (testset-testset.min())/(testset.max()-testset.min())\n",
        "\n",
        "# Convert trainset and testset and labels into numpy arrays\n",
        "trainset = np.asarray(normalizedTrainset)\n",
        "testset = np.asarray(normalizedTestset)\n",
        "\n",
        "trainlabels = np.asarray(trainlabels)\n",
        "testlabels = np.asarray(testlabels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgSw0QrmR-SL"
      },
      "source": [
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vw-lq6x4vdP"
      },
      "source": [
        "def predict(X, W, b):\n",
        "    return np.round(sigmoid(np.dot(X,W) + b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4qbZrP9RjAQ"
      },
      "source": [
        "def accuracy(cm):\n",
        "    tp = cm[0,0]\n",
        "    tn = cm[1,1]\n",
        "    fp = cm[1,0]\n",
        "    fn = cm[0,1]\n",
        "\n",
        "    return (tp + tn)/(tp+tn+fp+fn)\n",
        "def precision(cm):\n",
        "    tp = cm[0,0]\n",
        "    tn = cm[1,1]\n",
        "    fp = cm[1,0]\n",
        "    fn = cm[0,1]\n",
        "\n",
        "    return tp/(tp+fp)\n",
        "def recall(cm):\n",
        "    tp = cm[0,0]\n",
        "    tn = cm[1,1]\n",
        "    fp = cm[1,0]\n",
        "    fn = cm[0,1]\n",
        "\n",
        "    return tp/(tp+fn)\n",
        "def NPV(cm):\n",
        "    tp = cm[0,0]\n",
        "    tn = cm[1,1]\n",
        "    fp = cm[1,0]\n",
        "    fn = cm[0,1]\n",
        "\n",
        "    return tn/(tn+fn)\n",
        "def FPR(cm):\n",
        "    tp = cm[0,0]\n",
        "    tn = cm[1,1]\n",
        "    fp = cm[1,0]\n",
        "    fn = cm[0,1]\n",
        "\n",
        "    return fp/(tn+fp)\n",
        "def FDR(cm):\n",
        "    tp = cm[0,0]\n",
        "    tn = cm[1,1]\n",
        "    fp = cm[1,0]\n",
        "    fn = cm[0,1]\n",
        "\n",
        "    return fp/(tp+fp)\n",
        "def F1(cm):\n",
        "    return (2*precision(cm)*recall(cm))/(precision(cm)+recall(cm))\n",
        "def F2(cm):\n",
        "    return (5*precision(cm)*recall(cm))/((4*precision(cm))+recall(cm))\n",
        "def confusion_matrix(preds, y):\n",
        "    cm = np.zeros((2,2))\n",
        "    for i in range(y.shape[0]):\n",
        "        if preds[i] == 1 and y[i] == 1:\n",
        "            cm[0,0] += 1\n",
        "        if preds[i] == 0 and y[i] == 1:\n",
        "            cm[0,1] += 1\n",
        "        if preds[i] == 1 and y[i] == 0:\n",
        "            cm[1,0] += 1\n",
        "        if preds[i] == 0 and y[i] == 0:\n",
        "            cm[1,1] += 1\n",
        "    return cm\n",
        "\n",
        "def getAccuracies(preds, testlabels, learningRate, title):\n",
        "    print(\"Accuracies for \" , title, \" with \", learningRate)\n",
        "    cm = confusion_matrix(preds,testlabels)\n",
        "    acc = accuracy(cm)\n",
        "    prec = precision(cm)\n",
        "    rcl = recall(cm)\n",
        "    npv = NPV(cm)\n",
        "    fpr = FPR(cm)\n",
        "    fdr = FDR(cm)\n",
        "    f1 = F1(cm)\n",
        "    f2 = F2(cm)\n",
        "\n",
        "    print(\"Confusion Matrix = \", cm)\n",
        "    print(\"Accuracy = \", acc)\n",
        "    print(\"Precision = \", prec)\n",
        "    print(\"Recall = \", rcl)\n",
        "    print(\"Negative Predictive Value = \", npv)\n",
        "    print(\"False Positive Rate = \", fpr)\n",
        "    print(\"False Discovery Rate = \", fdr)\n",
        "    print(\"F1 Value = \", f1)\n",
        "    print(\"F2 Value = \", f2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK6FyX3iR1ep",
        "outputId": "2dc99f8b-57cf-4c6c-bf65-f60b7d2dde90"
      },
      "source": [
        "# Mini Batch Gradient Ascent\n",
        "def minibatch_ga(X, Y, batch_size, epochs, learningRate):\n",
        "    \n",
        "    samples = X.shape[0]\n",
        "    features = X.shape[1]\n",
        "\n",
        "    W = np.random.normal(0, 0.01, (features))\n",
        "    b = np.random.normal(0, 0.01)\n",
        "    # Start timer here to time training duration\n",
        "    start = time.time()\n",
        "    for i in range(epochs):\n",
        "        # Divide trainset into batches of size 32 and train\n",
        "        for k in range(samples // batch_size):\n",
        "\n",
        "            batch = X[k * batch_size : (k+1) * batch_size]\n",
        "            label = Y[k * batch_size : (k+1) * batch_size]\n",
        "\n",
        "            z = np.dot(batch, W) + b\n",
        "            a = sigmoid(z)\n",
        "\n",
        "            gradient = np.dot(batch.T, (label-a))/batch_size\n",
        "            W = W + learningRate * gradient\n",
        "            b = b + learningRate * (np.sum(label-a)/batch_size)\n",
        "\n",
        "    # Get duration\n",
        "    end = time.time()\n",
        "    print(\"Training took \", end-start)\n",
        "    return W, b\n",
        "\n",
        "W1, b1 = minibatch_ga(trainset, trainlabels, 32, 1000, 10**-4)\n",
        "preds1 = predict(testset, W1, b1)\n",
        "getAccuracies(preds1, testlabels, 10**-4, \"Mini Batch Gradient Ascent with Batch Size 32\")\n",
        "print(\"\\n\" * 3)\n",
        "W2, b2 = minibatch_ga(trainset, trainlabels, 32, 1000, 10**-3)\n",
        "preds2 = predict(testset, W2, b2)\n",
        "getAccuracies(preds2, testlabels, 10**-3, \"Mini Batch Gradient Ascent with Batch Size 32\")\n",
        "print(\"\\n\" * 3)\n",
        "W3, b3 = minibatch_ga(trainset, trainlabels, 32, 1000, 10**-2)\n",
        "preds3 = predict(testset, W3, b3)\n",
        "getAccuracies(preds3, testlabels, 10**-2, \"Mini Batch Gradient Ascent with Batch Size 32\")\n",
        "print(\"\\n\" * 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training took  0.5738558769226074\n",
            "Accuracies for  Mini Batch Gradient Ascent with Batch Size 32  with  0.0001\n",
            "Confusion Matrix =  [[  8.  61.]\n",
            " [  0. 110.]]\n",
            "Accuracy =  0.659217877094972\n",
            "Precision =  1.0\n",
            "Recall =  0.11594202898550725\n",
            "Negative Predictive Value =  0.6432748538011696\n",
            "False Positive Rate =  0.0\n",
            "False Discovery Rate =  0.0\n",
            "F1 Value =  0.20779220779220778\n",
            "F2 Value =  0.14084507042253522\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training took  0.5796158313751221\n",
            "Accuracies for  Mini Batch Gradient Ascent with Batch Size 32  with  0.001\n",
            "Confusion Matrix =  [[ 49.  20.]\n",
            " [ 10. 100.]]\n",
            "Accuracy =  0.8324022346368715\n",
            "Precision =  0.8305084745762712\n",
            "Recall =  0.7101449275362319\n",
            "Negative Predictive Value =  0.8333333333333334\n",
            "False Positive Rate =  0.09090909090909091\n",
            "False Discovery Rate =  0.1694915254237288\n",
            "F1 Value =  0.7656250000000001\n",
            "F2 Value =  0.7313432835820896\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training took  0.662522554397583\n",
            "Accuracies for  Mini Batch Gradient Ascent with Batch Size 32  with  0.01\n",
            "Confusion Matrix =  [[ 48.  21.]\n",
            " [  9. 101.]]\n",
            "Accuracy =  0.8324022346368715\n",
            "Precision =  0.8421052631578947\n",
            "Recall =  0.6956521739130435\n",
            "Negative Predictive Value =  0.8278688524590164\n",
            "False Positive Rate =  0.08181818181818182\n",
            "False Discovery Rate =  0.15789473684210525\n",
            "F1 Value =  0.761904761904762\n",
            "F2 Value =  0.7207207207207208\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8u_eYnyHtEe",
        "outputId": "94eaab70-996d-4e8f-9cd0-c279ba7d1686"
      },
      "source": [
        "# Full Batch Gradient Ascent\n",
        "def fullbatch_ga(X, Y, epochs, learningRate):\n",
        "\n",
        "    samples = X.shape[0]\n",
        "    features = X.shape[1]\n",
        "\n",
        "    W = np.random.normal(0, 0.01, (features))\n",
        "    # W = np.zeros(features)\n",
        "    b = np.random.normal(0, 0.01)\n",
        "    # Start timer here to time training duration\n",
        "    start = time.time()\n",
        "\n",
        "    for i in range(epochs):\n",
        "        # print(\"Epoch => \", i+1)\n",
        "        if(i%100 == 0 and i > 0):\n",
        "            print(\"Weights at epoch \", i, \" \" , W)\n",
        "        z = np.dot(X, W) + b\n",
        "        a = sigmoid(z)\n",
        "\n",
        "        gradient = np.dot(X.T, (Y-a))/samples\n",
        "        W = W + learningRate * gradient\n",
        "        b = b + learningRate * (np.sum(Y-a)/samples)\n",
        "\n",
        "    # Get duration\n",
        "    end = time.time()\n",
        "    print(\"Training took \", end-start)\n",
        "    return W,b\n",
        "\n",
        "W1, b1 = fullbatch_ga(trainset, trainlabels, 1000, 10**-4)\n",
        "preds1 = predict(testset, W1, b1)\n",
        "getAccuracies(preds1, testlabels, 10**-4, \"Full Batch Gradient Ascent\")\n",
        "print(\"\\n\" * 3)\n",
        "W2, b2 = fullbatch_ga(trainset, trainlabels, 1000, 10**-3)\n",
        "preds2 = predict(testset, W2, b2)\n",
        "getAccuracies(preds2, testlabels, 10**-3, \"Full Batch Gradient Ascent\")\n",
        "print(\"\\n\" * 3)\n",
        "W3, b3 = fullbatch_ga(trainset, trainlabels, 1000, 10**-2)\n",
        "preds3 = predict(testset, W3, b3)\n",
        "getAccuracies(preds3, testlabels, 10**-2, \"Full Batch Gradient Ascent\")\n",
        "print(\"\\n\" * 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights at epoch  100   [-0.01512347  0.00969282 -0.01048701 -0.01241675  0.01136307  0.00819097]\n",
            "Weights at epoch  200   [-0.01656913  0.01047752 -0.01104443 -0.01249236  0.01134338  0.00810724]\n",
            "Weights at epoch  300   [-0.01801079  0.0112635  -0.01159981 -0.01256765  0.01132397  0.00802453]\n",
            "Weights at epoch  400   [-0.01944847  0.01205078 -0.01215315 -0.01264264  0.01130485  0.00794281]\n",
            "Weights at epoch  500   [-0.0208822   0.01283933 -0.01270446 -0.01271732  0.011286    0.0078621 ]\n",
            "Weights at epoch  600   [-0.02231197  0.01362914 -0.01325374 -0.01279169  0.01126744  0.00778238]\n",
            "Weights at epoch  700   [-0.02373782  0.01442021 -0.01380102 -0.01286576  0.01124916  0.00770365]\n",
            "Weights at epoch  800   [-0.02515976  0.01521253 -0.01434629 -0.01293953  0.01123116  0.00762591]\n",
            "Weights at epoch  900   [-0.0265778   0.01600609 -0.01488956 -0.01301299  0.01121343  0.00754915]\n",
            "Training took  0.06705212593078613\n",
            "Accuracies for  Full Batch Gradient Ascent  with  0.0001\n",
            "Confusion Matrix =  [[ 26.  43.]\n",
            " [  1. 109.]]\n",
            "Accuracy =  0.7541899441340782\n",
            "Precision =  0.9629629629629629\n",
            "Recall =  0.37681159420289856\n",
            "Negative Predictive Value =  0.7171052631578947\n",
            "False Positive Rate =  0.00909090909090909\n",
            "False Discovery Rate =  0.037037037037037035\n",
            "F1 Value =  0.5416666666666667\n",
            "F2 Value =  0.4290429042904291\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Weights at epoch  100   [-0.00883156  0.03385398 -0.00493481  0.00416337 -0.00170148  0.00888653]\n",
            "Weights at epoch  200   [-0.0230078   0.04168983 -0.01034195  0.00342319 -0.00188103  0.00811521]\n",
            "Weights at epoch  300   [-0.03680368  0.04964554 -0.0155548   0.00271235 -0.00203372  0.00743935]\n",
            "Weights at epoch  400   [-0.05023475  0.05771301 -0.02058198  0.0020295  -0.00216091  0.00685442]\n",
            "Weights at epoch  500   [-0.063316    0.06588453 -0.02543178  0.0013733  -0.00226393  0.00635609]\n",
            "Weights at epoch  600   [-0.07606178  0.07415273 -0.03011212  0.00074251 -0.00234404  0.00594021]\n",
            "Weights at epoch  700   [-0.0884859   0.08251059 -0.03463062  0.00013589 -0.00240243  0.0056028 ]\n",
            "Weights at epoch  800   [-0.10060156  0.09095142 -0.03899455 -0.00044769 -0.00244027  0.00534004]\n",
            "Weights at epoch  900   [-0.11242144  0.09946884 -0.04321088 -0.00100935 -0.00245866  0.00514832]\n",
            "Training took  0.07317399978637695\n",
            "Accuracies for  Full Batch Gradient Ascent  with  0.001\n",
            "Confusion Matrix =  [[  2.  67.]\n",
            " [  0. 110.]]\n",
            "Accuracy =  0.6256983240223464\n",
            "Precision =  1.0\n",
            "Recall =  0.028985507246376812\n",
            "Negative Predictive Value =  0.6214689265536724\n",
            "False Positive Rate =  0.0\n",
            "False Discovery Rate =  0.0\n",
            "F1 Value =  0.05633802816901409\n",
            "F2 Value =  0.03597122302158273\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Weights at epoch  100   [-0.12706125  0.09861945 -0.05805993 -0.00556296 -0.01610551  0.00310749]\n",
            "Weights at epoch  200   [-0.2306939   0.18694101 -0.09330838 -0.01013188 -0.01535299  0.00453358]\n",
            "Weights at epoch  300   [-0.31533556  0.27775883 -0.11957449 -0.01342374 -0.01355928  0.01005405]\n",
            "Weights at epoch  400   [-0.38707707  0.36824573 -0.14015961 -0.01595714 -0.01123153  0.01796721]\n",
            "Weights at epoch  500   [-0.44977126  0.45674153 -0.15712446 -0.0180529  -0.00867919  0.02722275]\n",
            "Weights at epoch  600   [-0.5058872   0.54230478 -0.17176132 -0.01990957 -0.00608973  0.03717196]\n",
            "Weights at epoch  700   [-0.55703484  0.62443984 -0.1848847  -0.02164976 -0.003575    0.04741498]\n",
            "Weights at epoch  800   [-0.60428521  0.70292822 -0.19700996 -0.02334865 -0.00119962  0.05770727]\n",
            "Weights at epoch  900   [-0.64836748  0.77772243 -0.20846404 -0.02505158  0.0010013   0.06790175]\n",
            "Training took  0.07776761054992676\n",
            "Accuracies for  Full Batch Gradient Ascent  with  0.01\n",
            "Confusion Matrix =  [[ 32.  37.]\n",
            " [  1. 109.]]\n",
            "Accuracy =  0.7877094972067039\n",
            "Precision =  0.9696969696969697\n",
            "Recall =  0.463768115942029\n",
            "Negative Predictive Value =  0.7465753424657534\n",
            "False Positive Rate =  0.00909090909090909\n",
            "False Discovery Rate =  0.030303030303030304\n",
            "F1 Value =  0.6274509803921569\n",
            "F2 Value =  0.517799352750809\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js4z4kyjNsLZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}